{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598600120188",
   "display_name": "Python 3.7.7 64-bit ('datascience': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Pipeline Interface\n",
    "\n",
    "The Pipeline class is not restricted to preprocessing and classification. It could be anything like preprocessing pipeline, scaling pipeline etc.\n",
    "\n",
    "There are some requirement of the pipeline:\n",
    "\n",
    "* The last step if it's an estimator needs to have __transform__ method.\n",
    "* Internally during fit method each step perfoms fit and transform then the input of the next step is the transform output from previous step. Then at the last step it just call fit method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenient Pipeline Creation using make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pipe long steps\n [('scaler', MinMaxScaler()), ('svc', SVC())]\npipe short pipeline\n [('minmaxscaler', MinMaxScaler()), ('svc', SVC())]\npipe short 1 pipeline\n [('minmaxscaler-1', MinMaxScaler()), ('minmaxscaler-2', MinMaxScaler()), ('svc', SVC())]\n"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# standard pipeline\n",
    "pipe_long = Pipeline([('scaler', MinMaxScaler()), ('svc', SVC())])\n",
    "# short pipeline\n",
    "# this method create the name automatically\n",
    "pipe_short = make_pipeline(MinMaxScaler(), SVC())\n",
    "# if some steps uses the same class numbers added\n",
    "pipe_short_1 = make_pipeline(MinMaxScaler(), MinMaxScaler(), SVC())\n",
    "\n",
    "print(\"pipe long steps\\n {}\".format(pipe_long.steps))\n",
    "print(\"pipe short pipeline\\n {}\".format(pipe_short.steps))\n",
    "print(\"pipe short 1 pipeline\\n {}\".format(pipe_short_1.steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Steps Attributes\n",
    "\n",
    "say you want to extract the principal component from PCA. To access this you can use __named\\_steps__ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PCA components (2, 30)\n"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    " \n",
    "# create pipe with pca\n",
    "pipe = Pipeline([('standard-scaler1', StandardScaler()),('pca', PCA(n_components=2))])\n",
    "\n",
    "pipe.fit(cancer.data)\n",
    "components = pipe.named_steps[\"pca\"].components_\n",
    "print(\"PCA components {}\".format(components.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Steps Attributs in GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "print best estimator\n Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression(C=1))])\nLogisticRegression step\n LogisticRegression(C=1)\nLogreg coefs\n [[-0.29792942 -0.58056355 -0.3109406  -0.377129   -0.11984232  0.42855478\n  -0.71131106 -0.85371164 -0.46688191  0.11762548 -1.38262136  0.0899184\n  -0.94778563 -0.94686238  0.18575731  0.99305313  0.11090349 -0.3458275\n   0.20290919  0.80470317 -0.91626377 -0.91726667 -0.8159834  -0.86539197\n  -0.45539191  0.10347391 -0.83009341 -0.98445173 -0.5920036  -0.61086989]]\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"print best estimator\\n {}\".format(grid.best_estimator_))\n",
    "print(\"LogisticRegression step\\n {}\".format(grid.best_estimator_.named_steps['logisticregression']))\n",
    "# get the coefficients\n",
    "print(\"Logreg coefs\\n {}\".format(grid.best_estimator_.named_steps['logisticregression'].coef_))\n"
   ]
  }
 ]
}